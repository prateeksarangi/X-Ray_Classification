{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test', 'train', 'val']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "print(os.listdir(os.getcwd()+\"/chest_xray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'PNEUMONIA', 'NORMAL']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()+\"/chest_xray/train/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c857b24a29f6a9c08b97db1061d1ca787a2b903c"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = os.getcwd()+\"/chest_xray/train/\"\n",
    "TEST_DIR =  os.getcwd()+\"/chest_xray/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "693676686090d22160ab9c2f01ade2e3b276f2df"
   },
   "outputs": [],
   "source": [
    "def get_label(Dir):\n",
    "    for nextdir in os.listdir(Dir):\n",
    "        if not nextdir.startswith('.'):\n",
    "            if nextdir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextdir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "    return nextdir, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9ca7276d8b0491c0a80a07d2a62fad3f2191f916"
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for nextdir in os.listdir(Dir):\n",
    "        nextdir, label = get_label(Dir)\n",
    "        temp = Dir + nextdir\n",
    "        \n",
    "        for image_filename in tqdm(os.listdir(temp)):\n",
    "            path = os.path.join(temp + '/' , image_filename)\n",
    "            img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = skimage.transform.resize(img, (150, 150, 3))\n",
    "                img = np.asarray(img)\n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "            \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "70b9a29f77e86bc117c6cbbb56b8ef3351be0d8e"
   },
   "outputs": [],
   "source": [
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "                \n",
    "            temp = Dir + nextDir\n",
    "                \n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file)\n",
    "                if img is not None:\n",
    "                    img = skimage.transform.resize(img, (150, 150, 3))\n",
    "                    #img_file = scipy.misc.imresize(arr=img_file, size=(299, 299, 3))\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    y.append(label)\n",
    "                    \n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ac724e88df1a7a3045e4b94e6b21498230b093f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3876/3876 [49:28<00:00,  1.31it/s]     \n",
      "100%|██████████| 1342/1342 [11:49<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_data(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4f87ce1ada949fb741257569c2761cc4d7ed4264"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:55<00:00,  7.03it/s]\n",
      "100%|██████████| 234/234 [02:23<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test , y_test = get_data(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7b6282130ca6091b541670d6a34f63725ca1d0c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 150, 150, 3) \n",
      " (624, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,'\\n',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b5d30f44384d75880d8d7ca6a57e570e8025bd50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216,) \n",
      " (624,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,'\\n',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "78e6bd8959bde4dc63470dcca8e5c692e08a5a28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "29e7a18a73fbcdab4d54a8b85fe58fabc4b8a2ed"
   },
   "outputs": [],
   "source": [
    "Pimages = os.listdir(TRAIN_DIR + \"PNEUMONIA\")\n",
    "Nimages = os.listdir(TRAIN_DIR + \"NORMAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "69032bcfc05b40dd968aff77974a6f7a5c192f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Left) - No Pneumonia Vs (Right) - Pneumonia\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Left) - No Pneumonia Vs (Right) - Pneumonia\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Left) - No Pneumonia Vs (Right) - Pneumonia\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Left) - No Pneumonia Vs (Right) - Pneumonia\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Left) - No Pneumonia Vs (Right) - Pneumonia\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotter(i):\n",
    "    imagep1 = cv2.imread(TRAIN_DIR+\"PNEUMONIA/\"+Pimages[i])\n",
    "    imagep1 = skimage.transform.resize(imagep1, (150, 150, 3) , mode = 'reflect')\n",
    "    imagen1 = cv2.imread(TRAIN_DIR+\"NORMAL/\"+Nimages[i])\n",
    "    imagen1 = skimage.transform.resize(imagen1, (150, 150, 3))\n",
    "    pair = np.concatenate((imagen1, imagep1), axis=1)\n",
    "    print(\"(Left) - No Pneumonia Vs (Right) - Pneumonia\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "for i in range(5,10):\n",
    "    plotter(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "9e574dcb15d90d3d7ac16e6c6ec99870122fea8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwini/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "3bc49c68134527f941e377bc2951707391efa701"
   },
   "outputs": [],
   "source": [
    "filepath=\"transferlearning_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "e052d66b2bc0230cba4c258ca2b203c6ee3c49ff"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.common.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "93d0dc1d3cb51d33fe42061f9fd4a04622747359"
   },
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(5216,3,150,150)\n",
    "X_test=X_test.reshape(624,3,150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "b3e8e62ba15d81e498e99c343b1a2726c35f5d02"
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights=None, include_top=False , input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "a360cfa0fb59bdc0320654f4d2f8ebdf17699606"
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(2, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "802363ca2a8d86b07ee0ae5339f274204d098f9d"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 12 layers into a model with 188 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-62d3e0aac8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/ashwini/Downloads/con.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1228\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1230\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1207\u001b[0m                          \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                          \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                          str(len(filtered_layers)) + ' layers.')\n\u001b[0m\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 12 layers into a model with 188 layers."
     ]
    }
   ],
   "source": [
    "base_model.load_weights(\"/Users/ashwini/Downloads/con.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faaf2b3ccc4577a1055a4be288b6ec0e59fd1a91"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3e2aea33939fbddbbb74196e3e626c64eac6ee6"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture of  Layers. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf6a1570df7072b1854400be0e7fbf797e3f54f"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe3abae19909bb628acbf32bedf3f3e6e5c0f837"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98e83615fceafdd6c733bf579734647e16616122"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data = (X_test , y_test) ,callbacks=[lr_reduce,checkpoint] ,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9abdddbb4b318d827cbb76d408ca686108e4d2bc"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"transferlearning_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcb097634f5105372bbd0d7f65d6e75cc6db6807"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b58d4df389b2a2022c786676a6962992caf484c2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c66f57329ca29eda05a7d7a25bcbd7bd5da3b10"
   },
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_true, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "370 / (370 + 62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "370 / (370 + 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*0.9487*0.8564 / (0.9487 + 0.8564)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The f1 score is 90.01 % . The harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ba8ae0fe59e177b5b602ea37a3b008ebf660a84"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
